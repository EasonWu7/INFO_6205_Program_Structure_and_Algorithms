{
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernelspec": {
      "name": "python",
      "display_name": "Python (Pyodide)",
      "language": "python"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "INFO 6205 – Program Structures and Algorithms Assignment 3 Worked Solutions",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "student name:Fangyu Wu",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Professor: Nik Bear Brown",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question1 :Give a brief definitions for the following:\ni.critical path\n\nii.Monte Carlo method\n\niii.Heisenberg Uncertainty Principle\n\niv.Tragedy of the Commons\n\nv.Artificial Intelligence Ethics",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n\ni.critical path: The \"critical path\" in project management is a vital concept that plays a significant role in scheduling and completing a project. It refers to the sequence of tasks or activities within a project that, when delayed, will cause the project's overall timeline to be extended. In other words, the critical path represents the longest path through a project network, with the least amount of float or slack, which means there is no room for delay without affecting the project's completion date.\n\nii.Monte Carlo method:The \"Monte Carlo method\" is a computational technique used to estimate complex mathematical or physical problems using random sampling. It involves running simulations using random input values and then using statistical analysis of the results to approximate solutions. This method is widely used in various fields, including physics, finance, and engineering, to solve problems that are challenging to address analytically.\n\niii.Heisenberg Uncertainty Principle:The Heisenberg Uncertainty Principle is a fundamental concept in quantum mechanics that states it is impossible to simultaneously know the exact position and momentum (or velocity) of a particle with infinite precision. This principle implies that the more accurately one property is known (e.g., position), the less accurately the other property (e.g., momentum) can be known. It sets a limit on the precision of measurements in the quantum world.\n\niv.Tragedy of the Commons:The \"Tragedy of the Commons\" is a term used to describe a situation where individuals, acting in their self-interest, deplete shared or common resources to the detriment of the collective good. It illustrates the potential overuse and depletion of resources when there is no effective system in place for regulating access and use of those resources. This concept is often applied to environmental and resource management issues.\n\nv.Artificial Intelligence Ethics:\"Artificial Intelligence Ethics\" refers to the moral and ethical considerations surrounding the development, deployment, and use of artificial intelligence technologies. It involves addressing issues such as algorithmic bias, data privacy, accountability, transparency, and the impact of AI on society. Ethical AI practices aim to ensure that AI systems are designed and used in ways that align with societal values, respect human rights, and minimize harm.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question2:\n\nA --(3)--> B --(5)--> C\n|                   |\n|                   |\n(2)                 (7)\n|                   |\nv                   v\nD --(4)--> E --(6)--> F\n\nUse the Bellman-Ford algorithm to find the shortest path from node A to F in the weighted directed\ngraph above. Show your work.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n\n1.Initialize the distance to all nodes from the source node (A) as follows:\n\nA: 0 (the source node has a distance of 0).\nB, C, D, E, F: ∞ (initially, set all other nodes' distances to infinity).\n\n2.Start the Bellman-Ford algorithm:\n\na. Iterate through all edges of the graph:\n\nFrom A to B: The distance from A (0) plus the weight (3) is less than the current distance to B (∞), so update the distance to B as 3.\nFrom A to D: The distance from A (0) plus the weight (2) is less than the current distance to D (∞), so update the distance to D as 2.\nb. Repeat the iteration for each edge, updating distances as necessary until no more updates are possible.\n\n3.The distances after running the Bellman-Ford algorithm are as follows:\n\nA: 0\nB: 3\nC: 8\nD: 2\nE: 6\nF: 12\n\nThe shortest path from A to F is the path with the minimum distance. In this case, the shortest path from A to F is A -> B -> C -> E -> F with a total distance of 12.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question3:\n\nA --(10)--> B --(5)--> C\n|         |\n(15)      (5)\n|         |\nv         v\nD --(10)--> E\n\nUse the Ford-Fulkerson algorithm to find the maximum flow from node A to E in the weighted directed\ngraph above. Show your work.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer：\n1.Initialize flow on all edges to 0:\nA --(0/10)--> B --(0/5)--> C\n|                     |\n(0/15)                (0/5)\n|                     |\nv                     v\nD --(0/10)--> E\n\n2.Start the Ford-Fulkerson algorithm:\n\na. Find an augmenting path from A to E. An augmenting path is a path through the graph from the source (A) to the sink (E) in which the capacity of each edge on the path allows for additional flow.\n\nOne possible path is A -> B -> C -> E, with a minimum capacity of 5.\n\nb. Update the flow along the augmenting path by adding the minimum capacity (5) to each edge and subtracting it from the reverse edges:\n\nA --(5/10)--> B --(5/5)--> C\n|                     |\n(5/15)                (0/5)\n|                     |\nv                     v\nD --(5/10)--> E\n\nc. Repeat the process, finding augmenting paths and updating the flow, until no more augmenting paths can be found.\n\nOnce there are no more augmenting paths, the maximum flow has been reached. The flow in the network is as follows:\n\nA --(10/10)--> B --(5/5)--> C\n|                       |\n(15/15)                 (5/5)\n|                       |\nv                       v\nD --(10/10)--> E\n\nThe maximum flow from node A to E in this graph is 10 units.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question4:\n\nA --(16)--> B --(13)--> C\n|         |          |\n(4)       (10)       (9)\n|         |          |\nv         v          v\nD --(20)--> E --(7)--> F\n\nUsing the Push-Relabel algorithm, find the maximum flow from node A to F. Show your work.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n1.Initialize the preflow:\n\nSet a preflow value on each edge from A to its neighbors: A to B = 16, A to D = 4.\nInitialize the excess and height of each node: Excess = 0, Height = 0 for all nodes except A (Height = 6 for A).\n\n2.Find a valid preflow:\n\nInitially, A has excess = -20, B has excess = 16, C has excess = 0, D has excess = 4, E has excess = 0, and F has excess = 0.\n\n3.Find an overflowing node with the highest height (excluding the source and sink). In this case, it's B.\n\n4.Push excess from the overflowing node to a lower neighbor. Push as much flow as possible without violating the capacity constraint and respecting the height difference. In this step, we can push 13 units from B to C.\n\n5.The new excess values are: A (-20), B (3), C (13), D (4), E (0), F (0).\n\n6.Repeat steps 3-5 until there are no overflowing nodes left. In the next iteration, we might push 3 units from B to E.\n\n7.Continue iterating until there are no more overflowing nodes. The maximum flow is the sum of all the outflows from the source node, A. In this case, the maximum flow is 10 units.\n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question5:You are given a flow network represented by a directed graph G = (V, E) with a source vertex s ∈ V and a target/sink vertex t ∈ V. Each edge e ∈ E has a capacity ce, and each edge also has a cost associated with it, represented by cost ce. Your goal is to find a subset of edges M from E with a total capacity of at most k, such that the flow from s to t in the modified network G' = (V, E - M) is maximized.\n\nDesign a polynomial-time algorithm to solve this problem, optimizing the flow from s to t in G' while respecting the capacity constraint.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n1.Initialize the flow network G.\n\n2.Initialize the flow f to zero on all edges in G.\n\n3.Use the Ford-Fulkerson algorithm to find the maximum flow in the network G.\n\n4.Calculate the minimum cut in the network, which represents a subset of edges M with the maximum flow from s to t. These edges form the cut with the smallest capacity.\n\n5.If the capacity of this minimum cut is less than or equal to k, you have found the subset M with the desired properties.\n\n6.If the capacity of the minimum cut is greater than k, you can iteratively remove the edge with the highest cost from the minimum cut until the total capacity is at most k. This will minimize the flow from s to t in G' while respecting the capacity constraint.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question6:You are tasked with distributing a set of n packages to k delivery trucks in a way that minimizes the total distance traveled while ensuring that each truck carries at most [n/k] packages. Each package has a specific delivery location, and each truck has a maximum capacity for the number of packages it can carry.\n\nDesign a polynomial-time algorithm to determine if it is possible to distribute the packages to the trucks while meeting these constraints.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer：\n1.Create a bipartite graph with n nodes on the left representing the packages and k nodes on the right representing the trucks.\n\n2.Add edges between the packages and the trucks, with the edge weights representing the distance from the package's location to the truck's location. If the distance is greater than the allowed travel time for a truck, set the edge weight to infinity to indicate that it's not a feasible assignment.\n\n3.Run a maximum flow algorithm on the constructed graph, aiming to maximize the total distance traveled. The source node is connected to all the packages, and the sink node is connected to all the trucks.\n\n4.The flow in the network represents the assignments of packages to trucks. If the maximum flow value is equal to the total number of packages (n), and the flow satisfies the capacity constraint (each truck has at most [n/k] packages), then a feasible distribution is possible.\n\n5.If a feasible distribution is found, the algorithm provides the assignment of packages to trucks, and the minimum total distance traveled.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question7:You are tasked with selecting a subset of locations to open shops along a straight road with N blocks. Each location, i, has a potential profit of pi > 0, and you want to maximize the total profit of the locations you choose. However, you cannot open shops on adjacent blocks.\n\nDesign a dynamic programming algorithm to find the maximum profit achievable by selecting a subset of locations while adhering to the adjacency constraint.\n\n1.1 Define the Sub Problems\nLet OPT(i) be the maximum profit achievable from opening locations only on blocks 1 . . . i.\n\n1.2 Present Your Recurrence\nTODO: Give a recurrence for OPT(i).\n\n1.3 Prove your recurrence is correct\nTODO: Prove your recurrence is correct.\n\n1.4 State and Prove Base Cases\nTODO: State base case(s) for your recurrence.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n\n1.2 Present Your Recurrence\nOPT(i) = max(OPT(i-1), OPT(i-2) + pi)\nHere, OPT(i-1) represents the maximum profit achievable without opening a shop on block i, and OPT(i-2) + pi represents the maximum profit achievable by opening a shop on block i, considering the adjacency constraint.\n\n1.3 Prove your recurrence is correct\nWe can prove the correctness of the recurrence as follows:\n\nIf we choose not to open a shop on block i (OPT(i-1)), the profit for block i is excluded, and we are looking for the maximum profit achievable on the previous i-1 blocks.\n\nIf we choose to open a shop on block i (OPT(i-2) + pi), the profit for block i is added to the maximum profit achievable on the i-2 blocks before block i to ensure that the adjacency constraint is satisfied.\n\nTherefore, the recurrence captures the choice of opening a shop or not on block i, considering the adjacency constraint, and maximizes the total profit.\n\n1.4 State and Prove Base Cases\nThe base cases for the recurrence are as follows:\nOPT(0) = 0\nOPT(1) = p1\nOPT(0) represents no blocks, so the maximum profit is 0. OPT(1) represents the first block, and the maximum profit is the profit of the first block (p1).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question8:For each of the following recurrences, give an expression for the runtime T(n) if the recurrence can be\nsolved with the Master Theorem. Otherwise, indicate that the Master Theorem does not apply.\n\ni. T(n) = 4T (n/2)+ n2 log n\nii. T(n) = 2T (n/4)+ n0.5\niii. T(n) = 0.1n T (n/4) + log n\niv. T(n) = 9T (n/2)− n3\nv. T(n) = n2 T (n/3) + n",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\ni. T(n) = 4T (n/2)+ n2 log n\nThis recurrence falls into the category of the Master Theorem. It has the form T(n) = aT(n/b) + f(n), where a = 4, b = 2, and f(n) = n^2 log n. You can compare log_b(a) with the exponent in f(n) to determine the case. In this case, log_2(4) = 2, which is equal to the exponent in f(n). So, this is a case 2 scenario. The runtime complexity is O(n^2 log^2 n).\n\nii. T(n) = 2T (n/4)+ n0.5\nThis recurrence doesn't fit the standard form for the Master Theorem. The Master Theorem is applicable to recurrences of the form T(n) = aT(n/b) + f(n), where a, b, and f(n) are constants. In this case, the exponent in f(n) (0.5) is less than the logarithmic factor, and it doesn't align with the standard form.\n\niii. T(n) = 0.1n T (n/4) + log n\nThis recurrence also doesn't fit the standard form for the Master Theorem. The Master Theorem is not applicable here because it is not in the standard form. The coefficient (0.1n) in front of T(n/4) and the logarithmic term make it non-standard.\n\niv. T(n) = 9T (n/2)− n3\nThis recurrence falls into the category of the Master Theorem. It has the form T(n) = aT(n/b) + f(n), where a = 9, b = 2, and f(n) = -n^3. You can compare log_b(a) with the exponent in f(n) to determine the case. In this case, log_2(9) is greater than the exponent in f(n), which is 3. So, this is a case 3 scenario. The runtime complexity is O(n^3).\n\nv. T(n) = n2 T (n/3) + n\nThis recurrence also falls into the category of the Master Theorem. It has the form T(n) = aT(n/b) + f(n), where a = 1, b = 3, and f(n) = n. You can compare log_b(a) with the exponent in f(n) to determine the case. In this case, log_3(1) is less than the exponent in f(n), which is 1. So, this is a case 1 scenario. The runtime complexity is O(n^2).",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question9:You are given a set of intervals, each with a start time, end time, and an associated value. Your goal is to select a subset of non-overlapping intervals to maximize the combined value. Two intervals are considered non-overlapping if their time ranges do not overlap.\n\nInterval   Start Time   End Time  Value\nA              1           4        5\nB              2           6        8\nC              5           7        4\nD              8          10        6\nE              9          12        3",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n1.Sort the intervals by their end times in ascending order.\n\n2.Create an array dp to store the maximum value achievable up to and including each interval.\n\n3.Initialize dp[0] with the value of the first interval (since it's the only choice).\n\n4.Iterate through the sorted intervals starting from the second interval:\n\nFor each interval i, find the latest non-overlapping interval j to the left of i (with an end time less than or equal to the start time of i).\n\nUpdate dp[i] to be the maximum of either dp[i-1] (the maximum value without the current interval) or dp[j] + value[i] (the maximum value with the current interval).\n\n5.The maximum combined value will be in dp[n-1], where n is the number of intervals.",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Question10:You have a set of items, each with an associated weight and value. Your goal is to select a subset of items to maximize the combined value while ensuring that the total weight of the selected items does not exceed a given weight limit, W. Use dynamic programming to solve this problem.\n\nItem  Value (vi) Weight (wi)\n1       2          3\n2       3          4\n3       4          2\n4       3          2\n5       5          5\nCapacity of Knapsack W: 9",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Answer:\n1.Create a 2D array, dp, with dimensions (n+1) x (W+1), where n is the number of items, and W is the capacity of the knapsack. Initialize all values to zero.\n\n2.Iterate through the items, from 1 to n, and for each item i, iterate through the knapsack weights, from 1 to W.\n\n3.For each item i and weight w, consider two possibilities:\n\nIf the weight of item i (wi) is less than or equal to w, you have two choices:\nInclude item i in the knapsack: Add its value (vi) to the value obtained with the remaining capacity (dp[i-1][w-wi]).\nExclude item i from the knapsack: The value remains the same (dp[i-1][w]).\nTake the maximum of these two choices and store it in dp[i][w].\nIf the weight of item i (wi) is greater than w, you can't include it, so the value is the same as if you excluded it (dp[i][w] = dp[i-1][w]).\n\n4.The maximum combined value that can fit in the knapsack with capacity W is stored in dp[n][W].",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "",
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Reflection:\n1.I figure out what the underlying algorithmic concept of the problem is based on the sample problem provided, then learn this algorithmic concept from chatgpt, try to write some structure of the problem, bring in the appropriate data, and ultimately bring it into chatgpt to validate the soundness of the problem and modify it\n\n2.Firstly I may have too little knowledge of algorithmic concepts and need a lot of time to learn them, and secondly I need to innovate on the topic, which requires me to thoroughly understand the underlying algorithmic concepts of the topic.\n\n3.I learned the following knowledge of algorithmic problems through this assignment:\n1.Basic Concepts of Dynamic Programming: I learn the fundamental concepts of dynamic programming, such as breaking down a large problem into subproblems and using solutions to subproblems to construct the solution to the overall problem.\n\n2.Recurrence Relations: I see how to establish recurrence relations that describe the relationship between the solution of a problem and the solutions of its subproblems. Recurrence relations are crucial in dynamic programming.\n\n3.Maximization Problems: These problems all involve finding the maximum value, i.e., how to select a subset from a set of options to maximize the value of an objective function. This is a common application of dynamic programming.\n\n4.Constraints: I learn how to consider constraints in dynamic programming problems. These constraints often involve capacities, weight limits, or time constraints that you must satisfy when selecting the optimal subset.\n\n5.Dynamic Programming Algorithms: I understand how to use dynamic programming algorithms to solve these problems. These algorithms typically involve constructing dynamic programming tables, defining recurrence relations, populating the tables, and finding the optimal solutions.\n\n6.Master Theorem: For problems applicable to the Master Theorem, I learn how to use the Master Theorem to determine the time complexity of recursive problems.\n\n7.Complexity Analysis: I learn how to analyze the time complexity of algorithms, including using the Master Theorem to determine the time complexity of recursive algorithms.",
      "metadata": {}
    }
  ]
}